# 《数据密集型系统应用设计》小结

> 摘抄自原书各个章节的小结部分，并做部分精简

## 本书内容安排

全书分为三大部分：

1. 第一部分，主要讨论有关增强数据密集型应用系统所需的若干基本原则。

2. 第二部分，将从单机的数据存储转向跨机器的分布式系统，这是扩展性的重要一步，但随之而来的是各种挑战。

3. 第三部分，主要针对产生派生数据的系统，所谓派生数据主要指在异构系统中，如果无法用一个数据源来解决所有问题，那么一种自然的方式就是集成多个不同的数据库、缓存模块以及索引模块。

## 第一部分 数据系统基础

### 第 1 章 可靠、可扩展与可维护的应用系统

一个应用必须完成多种预期的需求，主要包括功能性需求（即应该做什么，如各种存储、检索、搜索和处理数据）和非功能性需求（即常规需求，如安全性、可靠性、合规性、可伸缩性、兼容性和可维护性）。本章着重讨论可靠性、可扩展性和可维护性。

可靠性意味着即使发生故障，系统也可以正常工作。故障包括硬件（通常是随机的，不想关的）、软件（缺陷通常是系统的，更加难以处理的）以及人为（总是很难避免时不时会出错）方面。容错技术可以很好地隐藏某种类型故障，避免影响最终用户。

可扩展性是指负载增加时，有效保持系统性能的相关技术策略。为了讨论可扩展性，我们首先讨论了如何**定量描述负载和性能**。简单地以Twitter浏览时间线为例描述负载，并将响应时间百分位数作为衡量性能的有效方式。对于可扩展的系统，增加处理能力的同时，还可以在高负载情况下持续保持系统的高可靠性。

可维护性则意味着许多方面，但究其本质是为了让工程和运营团队更为轻松。良好的抽象可以帮助降低复杂性，并使系统更易于修改和适配新场景。良好的可操作性意味着对系统健康状态有良好的可观测性和有效的管理方式。

然而知易行难，使应用程序可靠、可扩展或可维护并不容易。考虑到一些重要的模式和技术在很多不同的应用中普遍适用，在接下来几章中，就一些数据密集型系统例子，分析它们如何实现上述这些目标。

### 第 2 章 数据模型与查询语言

数据模型是一个庞大的主题，本章快速介绍了各种不同的数据模型，所有这三种模型（文档模型、关系模型和图模型），如今都已经广泛使用。我们观察到，一个模型可以用另一个模型来模拟。这就是为什么不同的模型用于不同的目的，而不是一个万能的解决方案。

文档数据库和图数据库有一个共同点，那就是它们通常不会对存储的数据强加某个模式，这可以使应用程序更容易适应不断变化的需求。但是应用程序可能仍然假定数据具有一定的结构，只不过是模式是显式（写时强制）还是隐式（读时处理）的问题。

每个数据模型都有自己的查询语言或框架，我们讨论来几个例子：SQL、MapReduce、MongoDB的聚合管道、Cypher、SPARQL和Datalog。还讨论来CSS和XPath，它们并不属于数据库查询语言，但存在相似之处。

虽然已经覆盖了很广的范围，但仍有一些数据模型尚未提及。

下一章将讨论在实现所描述的数据模型过程中有哪些重要的权衡设计。

### 第 3 章 数据存储与检索

本章简单介绍了数据库内部如何处理存储与检索。诸如，数据库存储数据新数据时会发生什么，以及之后查询数据时，数据库会做什么？

概括来讲，存储引擎分为两大类：针对事务处理（OLTP）的优化架构，以及针对分析性（OLAP）的优化架构。它们典型的访问模式存在很大差异：

- OLTP系统通常面向用户，这意味着它们可能收到大量的请求。为了处理负载，应用程序通常在每个查询中只涉及少量的记录。应用程序基于某种键来请求记录，而存储引擎使用索引来查找所请求键的数据。**磁盘寻道时间往往是瓶颈**。
- 由于不是直接面对最终用户，数据仓库和类似的分析型系统相比并不太广为人知，它们主要由业务分析师使用。处理的查询请求数目远低于OLTP系统，但是每个查询通常要求非常苛刻，需要在短时间内扫描数百万条记录。**磁盘带宽（不是寻道时间）常常是瓶颈**，而面向列的存储对于这种工作负载成为日益流行的解决方案。

在OLTP方面，有两个主要流派的存储引擎：

- 日志结构流派，它只允许追加式更新文件和删除过时的文件，但不会修改已写入的文件。
- 原地更新流派，将磁盘视为可以覆盖的一组固定大小的页。B-tree是一哲学的典型代表，它已用于所有主要的关系型数据库，以及大量的非关系型数据库。

日志结构的存储引擎是一个相对较新的方案。其关键思想是系统地将磁盘上随机访问写入转为顺序写入，由于硬盘驱动器和SSD的性能特性，可以实现更高的写入吞吐量。

此外，简要地介绍来一些更复杂的索引结构，以及为全内存而优化的数据库。

然后，从存储引擎的内部间接地探索来典型数据仓库的总体架构。由此说明为什么分析工作负载与OLTP如此不同：当查询需要在大量行中顺序扫描时，索引的关联性就会显著降低。相反，最重要的时非常紧凑地编码数据，以尽量减少磁盘读取的数据量。我们讨论来列存储如何帮助实现这一目标。

作为应用开发人员，掌握更多有关存储引擎内部的知识，可以更好地了解哪种工具最适合你的具体应用。如果还需要进一步调整数据库的可调参数，这些理解还可以帮助开发者正确评估调整参数所带来的影响。

**尽管本章不能让你成为某个特定存储引擎的调优专家，但希望帮你获得足够的知识与见解，以充分理解所选择的数据库。**

### 第 4 章 数据编码与演化

本章我们研究了将内存数据结构转换为网络或磁盘上的字节流的多种方法。我们看到这些编码的细节不仅影响其效率，更重要的是还影响应用程序的体系结构和部署时的支持选项。

特别地，许多服务需要支持滚动升级，即每次将新版本的服务逐步部署到几个节点，而不是同时部署到所有节点。滚动升级允许在不停机的情况下发布新版本的服务（因此鼓励频繁地发布小版本而不是大版本），并降低部署风险（允许错误版本在影响大量用户之前检测并回滚）。这些特性非常有利于应用程序的演化和更改。

在滚动升级期间，或者由于各种其他原因，必须假设不同的节点正在运行应用代码的不同版本。因此，在系统内流动的所有数据都以提供向后兼容性（新代码可以读取旧数据）和向前兼容性（旧代码可以读取新数据）的方式进行编码显得非常重要。

本章还讨论了多种数据编码格式及其兼容性情况：

- 编程语言特定的编码仅限于某一种编程语言，往往无法提供向前和向后兼容性。
- JSON、XML和CSV等文本格式非常普遍，其兼容性取决于你如何使用它们。
- 像Thrift、Protocol Buffer是和Avro这样的二进制的模式驱动格式，支持使用清晰定义的向前和向后兼容性语义进行紧凑、高效的编码。这些模式对于静态类型语言中文档和代码生成非常有用。然而有一个缺点，即只有在数据解码后才是人类可读的，

还讨论了数据流的几种模型，说明了数据编码在不同的场景下非常重要：

- 数据库、其中写入数据库的进程对数据进行编码，而读取数据库的进程对数据进行解码。
- RPC和REST API，其中客户端对请求进行编码，服务器对请求进行解码并对响应进行编码，客户端最终对响应进行解码。
- 异步消息传递（使用消息代理或Actor），节点之间通过互相发消息进行通信，消息有发送者编码并由接受者解码。

最后可以得出这样的结论，只要稍加小心，向后/向前兼容性和滚动升级是完全可以实现的。预祝所有人的应用程序可以快速迭代，顺利部署。
