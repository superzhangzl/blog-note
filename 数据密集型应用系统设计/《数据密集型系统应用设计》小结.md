# 《数据密集型系统应用设计》小结

> 摘抄自原书各个章节的小结部分，并做部分精简

## 本书内容安排

全书分为三大部分：

1. 第一部分，主要讨论有关增强数据密集型应用系统所需的若干基本原则。

2. 第二部分，将从单机的数据存储转向跨机器的分布式系统，这是扩展性的重要一步，但随之而来的是各种挑战。

3. 第三部分，主要针对产生派生数据的系统，所谓派生数据主要指在异构系统中，如果无法用一个数据源来解决所有问题，那么一种自然的方式就是集成多个不同的数据库、缓存模块以及索引模块。

## 第一部分 数据系统基础

### 第 1 章 可靠、可扩展与可维护的应用系统

一个应用必须完成多种预期的需求，主要包括功能性需求（即应该做什么，如各种存储、检索、搜索和处理数据）和非功能性需求（即常规需求，如安全性、可靠性、合规性、可伸缩性、兼容性和可维护性）。本章着重讨论可靠性、可扩展性和可维护性。

可靠性意味着即使发生故障，系统也可以正常工作。故障包括硬件（通常是随机的，不想关的）、软件（缺陷通常是系统的，更加难以处理的）以及人为（总是很难避免时不时会出错）方面。容错技术可以很好地隐藏某种类型故障，避免影响最终用户。

可扩展性是指负载增加时，有效保持系统性能的相关技术策略。为了讨论可扩展性，我们首先讨论了如何**定量描述负载和性能**。简单地以Twitter浏览时间线为例描述负载，并将响应时间百分位数作为衡量性能的有效方式。对于可扩展的系统，增加处理能力的同时，还可以在高负载情况下持续保持系统的高可靠性。

可维护性则意味着许多方面，但究其本质是为了让工程和运营团队更为轻松。良好的抽象可以帮助降低复杂性，并使系统更易于修改和适配新场景。良好的可操作性意味着对系统健康状态有良好的可观测性和有效的管理方式。

然而知易行难，使应用程序可靠、可扩展或可维护并不容易。考虑到一些重要的模式和技术在很多不同的应用中普遍适用，在接下来几章中，就一些数据密集型系统例子，分析它们如何实现上述这些目标。

### 第 2 章 数据模型与查询语言

数据模型是一个庞大的主题，本章快速介绍了各种不同的数据模型，所有这三种模型（文档模型、关系模型和图模型），如今都已经广泛使用。我们观察到，一个模型可以用另一个模型来模拟。这就是为什么不同的模型用于不同的目的，而不是一个万能的解决方案。

文档数据库和图数据库有一个共同点，那就是它们通常不会对存储的数据强加某个模式，这可以使应用程序更容易适应不断变化的需求。但是应用程序可能仍然假定数据具有一定的结构，只不过是模式是显式（写时强制）还是隐式（读时处理）的问题。

每个数据模型都有自己的查询语言或框架，我们讨论来几个例子：SQL、MapReduce、MongoDB的聚合管道、Cypher、SPARQL和Datalog。还讨论来CSS和XPath，它们并不属于数据库查询语言，但存在相似之处。

虽然已经覆盖了很广的范围，但仍有一些数据模型尚未提及。

下一章将讨论在实现所描述的数据模型过程中有哪些重要的权衡设计。

### 第 3 章 数据存储与检索

本章简单介绍了数据库内部如何处理存储与检索。诸如，数据库存储数据新数据时会发生什么，以及之后查询数据时，数据库会做什么？

概括来讲，存储引擎分为两大类：针对事务处理（OLTP）的优化架构，以及针对分析性（OLAP）的优化架构。它们典型的访问模式存在很大差异：

- OLTP系统通常面向用户，这意味着它们可能收到大量的请求。为了处理负载，应用程序通常在每个查询中只涉及少量的记录。应用程序基于某种键来请求记录，而存储引擎使用索引来查找所请求键的数据。**磁盘寻道时间往往是瓶颈**。
- 由于不是直接面对最终用户，数据仓库和类似的分析型系统相比并不太广为人知，它们主要由业务分析师使用。处理的查询请求数目远低于OLTP系统，但是每个查询通常要求非常苛刻，需要在短时间内扫描数百万条记录。**磁盘带宽（不是寻道时间）常常是瓶颈**，而面向列的存储对于这种工作负载成为日益流行的解决方案。

在OLTP方面，有两个主要流派的存储引擎：

- 日志结构流派，它只允许追加式更新文件和删除过时的文件，但不会修改已写入的文件。
- 原地更新流派，将磁盘视为可以覆盖的一组固定大小的页。B-tree是一哲学的典型代表，它已用于所有主要的关系型数据库，以及大量的非关系型数据库。

日志结构的存储引擎是一个相对较新的方案。其关键思想是系统地将磁盘上随机访问写入转为顺序写入，由于硬盘驱动器和SSD的性能特性，可以实现更高的写入吞吐量。

此外，简要地介绍来一些更复杂的索引结构，以及为全内存而优化的数据库。

然后，从存储引擎的内部间接地探索来典型数据仓库的总体架构。由此说明为什么分析工作负载与OLTP如此不同：当查询需要在大量行中顺序扫描时，索引的关联性就会显著降低。相反，最重要的时非常紧凑地编码数据，以尽量减少磁盘读取的数据量。我们讨论来列存储如何帮助实现这一目标。

作为应用开发人员，掌握更多有关存储引擎内部的知识，可以更好地了解哪种工具最适合你的具体应用。如果还需要进一步调整数据库的可调参数，这些理解还可以帮助开发者正确评估调整参数所带来的影响。

**尽管本章不能让你成为某个特定存储引擎的调优专家，但希望帮你获得足够的知识与见解，以充分理解所选择的数据库。**

### 第 4 章 数据编码与演化

本章我们研究了将内存数据结构转换为网络或磁盘上的字节流的多种方法。我们看到这些编码的细节不仅影响其效率，更重要的是还影响应用程序的体系结构和部署时的支持选项。

特别地，许多服务需要支持滚动升级，即每次将新版本的服务逐步部署到几个节点，而不是同时部署到所有节点。滚动升级允许在不停机的情况下发布新版本的服务（因此鼓励频繁地发布小版本而不是大版本），并降低部署风险（允许错误版本在影响大量用户之前检测并回滚）。这些特性非常有利于应用程序的演化和更改。

在滚动升级期间，或者由于各种其他原因，必须假设不同的节点正在运行应用代码的不同版本。因此，在系统内流动的所有数据都以提供向后兼容性（新代码可以读取旧数据）和向前兼容性（旧代码可以读取新数据）的方式进行编码显得非常重要。

本章还讨论了多种数据编码格式及其兼容性情况：

- 编程语言特定的编码仅限于某一种编程语言，往往无法提供向前和向后兼容性。
- JSON、XML和CSV等文本格式非常普遍，其兼容性取决于你如何使用它们。
- 像Thrift、Protocol Buffer是和Avro这样的二进制的模式驱动格式，支持使用清晰定义的向前和向后兼容性语义进行紧凑、高效的编码。这些模式对于静态类型语言中文档和代码生成非常有用。然而有一个缺点，即只有在数据解码后才是人类可读的，

还讨论了数据流的几种模型，说明了数据编码在不同的场景下非常重要：

- 数据库、其中写入数据库的进程对数据进行编码，而读取数据库的进程对数据进行解码。
- RPC和REST API，其中客户端对请求进行编码，服务器对请求进行解码并对响应进行编码，客户端最终对响应进行解码。
- 异步消息传递（使用消息代理或Actor），节点之间通过互相发消息进行通信，消息有发送者编码并由接受者解码。

最后可以得出这样的结论，只要稍加小心，向后/向前兼容性和滚动升级是完全可以实现的。预祝所有人的应用程序可以快速迭代，顺利部署。

## 第二部分 分布式数据系统

### 第 5 章 数据复制

复制或多副本技术主要服务于以下目的：

- 高可用性：即使某台机器（或多台机器，或整个数据中心）出现故障，系统也能保持正常运行。
- 连接断开与容错：允许应用程序在出现网络中断时继续工作。
- 低延迟：将数据放置在距离用户较近的地方，从而实现更快地交互。
- 可扩展性：采用多副本读取，大幅提高系统读操作的吞吐量。

在多台机器上保存多份相同的数据副本是复制技术上一个非常烧脑的问题，需要仔细考虑并发以及所有可能出错的关节，并小心处理故障之后的各种情形。最基本的，要处理好节点不可用与网络中断的问题，文中还没专门考虑一些更隐蔽的失效场景，例如由于软硬件bug导致的无提示的数据损坏。

本章主要讨论了三种多副本方案：

- 主从复制：所有的客户端写入操作都发送到某一个节点（主节点），由该节点负责将数据更改事件发送到其他副本（从节点）。每个副本都可以接收读取请求，但内容可能是过期值。
- 多主节点复制：系统存在多个主节点，每个都可以接收写请求，客户端将写请求发送到其中的一个主节点上，由该主节点负责将数据更改事件同步到其他主节点和自己的从节点。
- 无主节点复制：客户端将写请求发送到多个节点上，读取时从多个节点上并行读取，以此检测和纠正某些过期数据。

每种方法都有其优缺点。主从复制非常流行，主要是因为它很容易理解，也不需要担心冲突问题。而万一节点失效、网络中断或者延迟抖动等情况，多主节点和无主节点复制方案会更加可靠，不过背后的代价则是系统的复杂性和弱一致性的保证。

复制时可以同步的，也可以是异步的，而一旦发生故障，二者的变现差异会对系统行为产生深远的影响。在系统稳定状态下异步复制性能优秀，但仍须认真考虑一旦出现复制滞后和节点失效两种场景会导致何种影响。万一某个主节点发生故障，而一个异步更新的从节点被提升为新的主节点，要意识到最新确认的数据可能由丢失的风险。

本章还分析了由于复制滞后所引起的一些奇怪效应，并讨论了以下一致性模型，来帮助应用程序处理复制滞后：

- **写后读一致性**：保证用户总能看到自己所提交的最新数据。
- **单调读**：用户在某个事件点读到数据之后，保证此后不会出现比该时间点更早的数据。
- **前缀一致读**：保证数据之间的因果关系，例如：总是以正确的顺序先读取问题，然后看到回答。

最后本章讨论了多主节点和无主节点复制方案所引入的并发问题。即由于多个写可能同时发生，继而可能发生冲突。为此，研究了一个算法使得数据库系统可以判定某操作是否发生在另一个操作之前，或者是同时发生。接下来，探讨采用合并并发更新值的方法来解决冲突。

下一章将继续研究多节点上数据的分布问题，与本章不同的是，它是针对一个大型数据集而采用分区技术。

### 第 6 章 数据分区

本章探讨了将大规模数据集划分为更小子集的多种方法。数据量如果太大，单台机器进行存储和处理就会成为瓶颈，因此需要引入数据分区机制。分区的目的是通过多台机器均匀分布数据和查询负载，避免出现热点。这需要选择合适的数据分区方案，在节点添加或删除时重新动态平衡分区。

本章讨论了两种主要的分区方式：

- 基于关键字区间的分区。先对关键字进行排序，每个分区只负责一段包含最小到最大关键字范围的一段关键字。对关键字排序的有点事可以支持高效的区间查询，但是如果应用程序经常访问与排序一致的某段关键字，就会存在热点的风险，采用这种方法，当分区太大时，通常将其分裂为两个子区间，从而动态地再平衡分区。
- 哈希分区。将哈希函数作用于每个关键字，每个分区负责一定范围的哈希值。这种方法打破了原关键字的顺序关系，它的区间查询效率比较低，但可以更均匀地分配负载。采用哈希分区时，通常事先创建好足够多（但数量固定）的分区，让每个节点承担多个分区，当添加或删除节点时将某些分区从一个节点迁移到另一个节点，也可以只支持动态分区。

混合上述两种基本方法也是可行的，例如使用复合键：键的一部分来标识分区，而另一部分来记录排序后的顺序。

本章还讨论了分区和二级索引，二级索引也需要进去分区，有两种方法：

- 基于文档来分区二级索引（本地索引）。二级索引存储在与关键相同的分区中，这意味着写入时只需要更新一个分区，但缺点时读取二级索引时需要在所有分区上执行scatter/gather。
- 基于词条来分区二级索引（全局索引）。它是基于索引的值而进行的独立分区。二级索引中的条目可能包含来自关键字的多个分区里的记录。在写入时，不得不更新二级索引的多个分区；但读取时，则可以从单个分区直接快速读取数据。

最后讨论了如何将查询请求路由到正确的分区，包括简单的分区感知负载均衡器，以及复杂查询的并行查询执行引擎。

理论上，每个分区基本保持独立运行，这也是为什么我们试图将分区数据库分布、扩展到多台机器上。但是，如果写入需要跨多个分区，情况就会格外复杂，例如，如果其中一个分区写入成功，但另一个发生失败，接下来会发生什么？将在下面的章节中讨论类似这样的技术挑战。

### 第 7 章 事务

事务作为一个抽象层，使得应用程序可以忽略数据库内部一些复杂的并发问题，以及某些硬件、软件故障，从而简化应用层的处理逻辑，大量错误可以转化为简单的事务中止和应用层重试。

本章列举了很多事务能够预防的问题。尽管并非所有的应用程序都会面临这样问题，例如那些简单的访问模式，只读或者只写，可能根本无需事务的帮助。但对于复杂的访问模式，事务可以大大简化需要考虑潜在错误情况。

如果没有事务，各种错误情况（如进程崩溃、网络中断、停电、磁盘已满、并发竞争等）会导致数据可能出现各种不一致。例如，反序列化数据模式和相关操作会导致与源数据不同步。假如没有事务，处理那些复杂交互访问最后所导致的数据库混乱就会异常痛苦。

本章深入讨论了并发控制这一主题。介绍了多个广泛使用的隔离级别，特别是读-提交、快照隔离（或可重复读取）与可串行化。通过分析如何处理这些边界条件来阐述这些隔离级别的要点：

- **脏读**：客户端读到了其他客户端尚未提交的写入。读-提交以及更强的隔离级别可以防止脏读。
- **脏写**：客户端覆盖了另一个客户端尚未提交的写入。几乎所有的数据库实现都可以防止脏写。
- **读倾斜（不可重复读）**：客户在不同的时间点看到了不同值。快照隔离时最有用的防范手段，即事务总是在某个时间点的一致性快照中读取数据。通常采用多版本并发控制（MVCC）来实现快照隔离。
- **更新丢失**：两个客户端同时执行读-修改-写入操作序列，出现了其中一个覆盖了另一个的写入，但又没有包含对方最新值的情况，最终导致了部分修改数据发生了丢失。快照隔离的一些实现可以自动防止这种异常，而另一些则需要手动锁定查询结果（SELECT FOR UPDATE）。
- **写倾斜**：事务首先查询数据，根据返回的结果而做出某些决定，然后修改数据库。当事务提交时，支持决定的前提条件已不再成立。只有可串行化的隔离才能防止这种异常。
- **幻读**：事务读取了某些符合查询条件的对象，同时另一个客户端执行写入，改变了先前的查询结果。快照隔离可以防止简单的幻读，但写倾斜情况则需要特殊处理，例如采用区间锁。

弱隔离级别可以防止上面的某些异常，但还需要应用开发人员手动处理其他复杂情况（例如，显式加锁）。只有可串行化的隔离可以防止所有这些问题。本章主要讨论了实现可串行化隔离的三种不同方法：

- **严格串行执行事务**：如果每个事务的执行速度非常快，且单个CPU核可以满足事务的吞吐量要求，严格串行执行是一个非常简单有效的方案。
- **两阶段加锁**：几十年来，这一直是实现可串行化的标准方式，但还是又很多系统出于性能原因而放弃使用它。
- **可串行化的快照隔离（SSI）**：一种最新的算法，可以避免前面方法的大部分缺点。它秉持乐观预期的原则，允许许多个事务并发执行而不互相阻塞；仅当事务尝试提交时，才检查可能的冲突，如果发现违背了串行化，则某些事务会被中止。

本章中的示例都采用关系数据模型。但是，正如本章前面的"多对象事务的需求"所描述的，无论对哪种数据模型，事务都是非常有用的数据库功能。

本章所介绍的算法、方案主要针对单节点。对于分布式数据库，还会面临更多、更复杂的挑战，将在接下来的两章中继续展开讨论。