# 《数据密集型系统应用设计》小结

> 摘抄自原书各个章节的小结部分，并做部分精简

## 本书内容安排

全书分为三大部分：

1. 第一部分，主要讨论有关增强数据密集型应用系统所需的若干基本原则。

2. 第二部分，将从单机的数据存储转向跨机器的分布式系统，这是扩展性的重要一步，但随之而来的是各种挑战。

3. 第三部分，主要针对产生派生数据的系统，所谓派生数据主要指在异构系统中，如果无法用一个数据源来解决所有问题，那么一种自然的方式就是集成多个不同的数据库、缓存模块以及索引模块。

## 第一部分 数据系统基础

### 第 1 章 可靠、可扩展与可维护的应用系统

一个应用必须完成多种预期的需求，主要包括功能性需求（即应该做什么，如各种存储、检索、搜索和处理数据）和非功能性需求（即常规需求，如安全性、可靠性、合规性、可伸缩性、兼容性和可维护性）。本章着重讨论可靠性、可扩展性和可维护性。

可靠性意味着即使发生故障，系统也可以正常工作。故障包括硬件（通常是随机的，不想关的）、软件（缺陷通常是系统的，更加难以处理的）以及人为（总是很难避免时不时会出错）方面。容错技术可以很好地隐藏某种类型故障，避免影响最终用户。

可扩展性是指负载增加时，有效保持系统性能的相关技术策略。为了讨论可扩展性，我们首先讨论了如何**定量描述负载和性能**。简单地以Twitter浏览时间线为例描述负载，并将响应时间百分位数作为衡量性能的有效方式。对于可扩展的系统，增加处理能力的同时，还可以在高负载情况下持续保持系统的高可靠性。

可维护性则意味着许多方面，但究其本质是为了让工程和运营团队更为轻松。良好的抽象可以帮助降低复杂性，并使系统更易于修改和适配新场景。良好的可操作性意味着对系统健康状态有良好的可观测性和有效的管理方式。

然而知易行难，使应用程序可靠、可扩展或可维护并不容易。考虑到一些重要的模式和技术在很多不同的应用中普遍适用，在接下来几章中，就一些数据密集型系统例子，分析它们如何实现上述这些目标。

### 第 2 章 数据模型与查询语言

数据模型是一个庞大的主题，本章快速介绍了各种不同的数据模型，所有这三种模型（文档模型、关系模型和图模型），如今都已经广泛使用。我们观察到，一个模型可以用另一个模型来模拟。这就是为什么不同的模型用于不同的目的，而不是一个万能的解决方案。

文档数据库和图数据库有一个共同点，那就是它们通常不会对存储的数据强加某个模式，这可以使应用程序更容易适应不断变化的需求。但是应用程序可能仍然假定数据具有一定的结构，只不过是模式是显式（写时强制）还是隐式（读时处理）的问题。

每个数据模型都有自己的查询语言或框架，我们讨论来几个例子：SQL、MapReduce、MongoDB的聚合管道、Cypher、SPARQL和Datalog。还讨论来CSS和XPath，它们并不属于数据库查询语言，但存在相似之处。

虽然已经覆盖了很广的范围，但仍有一些数据模型尚未提及。

下一章将讨论在实现所描述的数据模型过程中有哪些重要的权衡设计。

### 第 3 章 数据存储与检索

本章简单介绍了数据库内部如何处理存储与检索。诸如，数据库存储数据新数据时会发生什么，以及之后查询数据时，数据库会做什么？

概括来讲，存储引擎分为两大类：针对事务处理（OLTP）的优化架构，以及针对分析性（OLAP）的优化架构。它们典型的访问模式存在很大差异：

- OLTP系统通常面向用户，这意味着它们可能收到大量的请求。为了处理负载，应用程序通常在每个查询中只涉及少量的记录。应用程序基于某种键来请求记录，而存储引擎使用索引来查找所请求键的数据。**磁盘寻道时间往往是瓶颈**。
- 由于不是直接面对最终用户，数据仓库和类似的分析型系统相比并不太广为人知，它们主要由业务分析师使用。处理的查询请求数目远低于OLTP系统，但是每个查询通常要求非常苛刻，需要在短时间内扫描数百万条记录。**磁盘带宽（不是寻道时间）常常是瓶颈**，而面向列的存储对于这种工作负载成为日益流行的解决方案。

在OLTP方面，有两个主要流派的存储引擎：

- 日志结构流派，它只允许追加式更新文件和删除过时的文件，但不会修改已写入的文件。
- 原地更新流派，将磁盘视为可以覆盖的一组固定大小的页。B-tree是一哲学的典型代表，它已用于所有主要的关系型数据库，以及大量的非关系型数据库。

日志结构的存储引擎是一个相对较新的方案。其关键思想是系统地将磁盘上随机访问写入转为顺序写入，由于硬盘驱动器和SSD的性能特性，可以实现更高的写入吞吐量。

此外，简要地介绍来一些更复杂的索引结构，以及为全内存而优化的数据库。

然后，从存储引擎的内部间接地探索来典型数据仓库的总体架构。由此说明为什么分析工作负载与OLTP如此不同：当查询需要在大量行中顺序扫描时，索引的关联性就会显著降低。相反，最重要的时非常紧凑地编码数据，以尽量减少磁盘读取的数据量。我们讨论来列存储如何帮助实现这一目标。

作为应用开发人员，掌握更多有关存储引擎内部的知识，可以更好地了解哪种工具最适合你的具体应用。如果还需要进一步调整数据库的可调参数，这些理解还可以帮助开发者正确评估调整参数所带来的影响。

**尽管本章不能让你成为某个特定存储引擎的调优专家，但希望帮你获得足够的知识与见解，以充分理解所选择的数据库。**

### 第 4 章 数据编码与演化

本章我们研究了将内存数据结构转换为网络或磁盘上的字节流的多种方法。我们看到这些编码的细节不仅影响其效率，更重要的是还影响应用程序的体系结构和部署时的支持选项。

特别地，许多服务需要支持滚动升级，即每次将新版本的服务逐步部署到几个节点，而不是同时部署到所有节点。滚动升级允许在不停机的情况下发布新版本的服务（因此鼓励频繁地发布小版本而不是大版本），并降低部署风险（允许错误版本在影响大量用户之前检测并回滚）。这些特性非常有利于应用程序的演化和更改。

在滚动升级期间，或者由于各种其他原因，必须假设不同的节点正在运行应用代码的不同版本。因此，在系统内流动的所有数据都以提供向后兼容性（新代码可以读取旧数据）和向前兼容性（旧代码可以读取新数据）的方式进行编码显得非常重要。

本章还讨论了多种数据编码格式及其兼容性情况：

- 编程语言特定的编码仅限于某一种编程语言，往往无法提供向前和向后兼容性。
- JSON、XML和CSV等文本格式非常普遍，其兼容性取决于你如何使用它们。
- 像Thrift、Protocol Buffer是和Avro这样的二进制的模式驱动格式，支持使用清晰定义的向前和向后兼容性语义进行紧凑、高效的编码。这些模式对于静态类型语言中文档和代码生成非常有用。然而有一个缺点，即只有在数据解码后才是人类可读的，

还讨论了数据流的几种模型，说明了数据编码在不同的场景下非常重要：

- 数据库、其中写入数据库的进程对数据进行编码，而读取数据库的进程对数据进行解码。
- RPC和REST API，其中客户端对请求进行编码，服务器对请求进行解码并对响应进行编码，客户端最终对响应进行解码。
- 异步消息传递（使用消息代理或Actor），节点之间通过互相发消息进行通信，消息有发送者编码并由接受者解码。

最后可以得出这样的结论，只要稍加小心，向后/向前兼容性和滚动升级是完全可以实现的。预祝所有人的应用程序可以快速迭代，顺利部署。

## 第二部分 分布式数据系统

### 第 5 章 数据复制

复制或多副本技术主要服务于以下目的：

- 高可用性：即使某台机器（或多台机器，或整个数据中心）出现故障，系统也能保持正常运行。
- 连接断开与容错：允许应用程序在出现网络中断时继续工作。
- 低延迟：将数据放置在距离用户较近的地方，从而实现更快地交互。
- 可扩展性：采用多副本读取，大幅提高系统读操作的吞吐量。

在多台机器上保存多份相同的数据副本是复制技术上一个非常烧脑的问题，需要仔细考虑并发以及所有可能出错的关节，并小心处理故障之后的各种情形。最基本的，要处理好节点不可用与网络中断的问题，文中还没专门考虑一些更隐蔽的失效场景，例如由于软硬件bug导致的无提示的数据损坏。

本章主要讨论了三种多副本方案：

- 主从复制：所有的客户端写入操作都发送到某一个节点（主节点），由该节点负责将数据更改事件发送到其他副本（从节点）。每个副本都可以接收读取请求，但内容可能是过期值。
- 多主节点复制：系统存在多个主节点，每个都可以接收写请求，客户端将写请求发送到其中的一个主节点上，由该主节点负责将数据更改事件同步到其他主节点和自己的从节点。
- 无主节点复制：客户端将写请求发送到多个节点上，读取时从多个节点上并行读取，以此检测和纠正某些过期数据。

每种方法都有其优缺点。主从复制非常流行，主要是因为它很容易理解，也不需要担心冲突问题。而万一节点失效、网络中断或者延迟抖动等情况，多主节点和无主节点复制方案会更加可靠，不过背后的代价则是系统的复杂性和弱一致性的保证。

复制时可以同步的，也可以是异步的，而一旦发生故障，二者的变现差异会对系统行为产生深远的影响。在系统稳定状态下异步复制性能优秀，但仍须认真考虑一旦出现复制滞后和节点失效两种场景会导致何种影响。万一某个主节点发生故障，而一个异步更新的从节点被提升为新的主节点，要意识到最新确认的数据可能由丢失的风险。

本章还分析了由于复制滞后所引起的一些奇怪效应，并讨论了以下一致性模型，来帮助应用程序处理复制滞后：

- **写后读一致性**：保证用户总能看到自己所提交的最新数据。
- **单调读**：用户在某个事件点读到数据之后，保证此后不会出现比该时间点更早的数据。
- **前缀一致读**：保证数据之间的因果关系，例如：总是以正确的顺序先读取问题，然后看到回答。

最后本章讨论了多主节点和无主节点复制方案所引入的并发问题。即由于多个写可能同时发生，继而可能发生冲突。为此，研究了一个算法使得数据库系统可以判定某操作是否发生在另一个操作之前，或者是同时发生。接下来，探讨采用合并并发更新值的方法来解决冲突。

下一章将继续研究多节点上数据的分布问题，与本章不同的是，它是针对一个大型数据集而采用分区技术。
